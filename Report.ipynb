{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19822dce-8cf9-46af-bfa2-8a631a1eb1f7",
   "metadata": {},
   "source": [
    "# Film development for PProductions: predicting IMDb ratings - Report\n",
    "\n",
    "## Author: Letícia Zorzi Rama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c730a-b46a-4ba6-b01a-dd2e22efa9e4",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis (EDA) - Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b849b-eec4-4e94-8653-f50571d44993",
   "metadata": {},
   "source": [
    "#### 2.a. Recommended movie for someone unknown\n",
    "\n",
    "The recommended movie for someone unknown is:\n",
    "\n",
    "1. ***The Godfather***, released in 1972, 175.0 min., directed by Francis Ford Coppola.\n",
    "\n",
    "Extra insight! The top 10 most recommended movies for someone unknown (without the first):\n",
    "\n",
    "2. *The Dark Knight*, released in 2008, 152.0 min., directed by Christopher Nolan.\n",
    "3. *The Lord of the Rings*: The Return of the King, released in 2003, 201.0 min., directed by Peter Jackson.\n",
    "5. *Pulp Fiction*, released in 1994, 154.0 min., directed by Quentin Tarantino.\n",
    "6. *The Lord of the Rings: The Fellowship of the Ring*, released in 2001, 178.0 min., directed by Peter Jackson.\n",
    "7. *Schindler's List*, released in 1993, 195.0 min., directed by Steven Spielberg.\n",
    "8. *The Godfather: Part II*, released in 1974, 202.0 min., directed by Francis Ford Coppola.\n",
    "9. *Forrest Gump*, released in 1994, 142.0 min., directed by Robert Zemeckis.\n",
    "10. *Inception*, released in 2010, 148.0 min., directed by Christopher Nolan.\n",
    "11. *The Lord of the Rings: The Two Towers*, released in 2002, 179.0 min., directed by Peter Jackson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd64a0b-05ab-4de8-9430-6e1f78f12af8",
   "metadata": {},
   "source": [
    "#### 2.b. Main factors related to a film's high grossing expectations\n",
    "\n",
    "- `gross` and `no_of_votes` correlate strongly positive (ρ ≈ 0.6): movies with high gross reach a lot of people, and get more number of votes\n",
    "- `gross` and `budget` correlate strongly positive (ρ ≈ 0.6): higher budgets allow higher production value & marketing spend, enabling high gross, although doesn’t guarantee it\n",
    "- `gross` and `revenue` correlate even strongly positive (ρ ≈ 0.8): since gross is a subset of revenue\n",
    "  \n",
    "- `main_genre` is a related factor: Horror, Action, Family, Biography, and Adventure tend to have the highest gross\n",
    "- `certificate`: PG (Parental Guidance) movies tend to have the highest gross\n",
    "- `director`: Gareth Edwards, Anthony Russo, Josh Cooley, Roger Allers, and Tim Miller are the top 5 directors making high-grossing movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27c250-ba1d-4f82-bb73-295e50c89632",
   "metadata": {},
   "source": [
    "#### 2.c. Insights gained from the Overview column\n",
    "\n",
    "With the current TF-IDF + logistic regression approach, the model is not able to reliably infer the film’s genre from the ‘overview’ column. Because ‘Drama’ is overrepresented in the dataset, the classifier defaults to predicting this genre, while underrepresented genres are almost never predicted. \n",
    "\n",
    "This indicates that the ***imbalance in the dataset*** and the ***generic nature of overviews*** limit the predictive power of this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9fedf-634e-417d-9239-836da328a62f",
   "metadata": {},
   "source": [
    "### 3. Predicting IMDb ratings from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e21496-9ad6-4b6a-9d69-33c5a3a9c785",
   "metadata": {},
   "source": [
    "#### Type of problem\n",
    "This is a regression problem: predict a numeric and continuous target `imdb_rating` (float, usually between 0 and 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a5a23-99c5-49d5-a6e4-4f299dd7ecda",
   "metadata": {},
   "source": [
    "#### Variables used and/or their transformations\n",
    "\n",
    "- Numeric variables (some use directly, other with simple transforms):\n",
    "    - `meta_score`: strong signal of critics’ reception (keep numeric)\n",
    "    - `runtime`: consider a quadratic term if relationship non-linear (keep numeric)\n",
    "    - `no_of_votes`, `budget`, `revenue`: EDA shows heavy positive correlation with economic measures (use log). Reasoning: logs stabilize variance and reduce skew\n",
    "\n",
    "- Categorical variables:\n",
    "    - `main_genre`, `certificate`: one-hot encoding. EDA shows genre correlates with other economic measures\n",
    "    - `director`, `star1..star4`: target-encoding (smoothed mean of the target `imdb_rating`). This captures reputation without exploding dimensionality. Reasoning: Many directors/actors have very few movies in the dataset — smoothing prevents high variance estimates\n",
    "\n",
    "- Text features:\n",
    "    - `overview`: TF-IDF (max_features=5–10k) then TruncatedSVD to keep first ~10 components (dense numeric summary). Reasoning: EDA showed TF-IDF + logistic regression couldn’t reliably infer genre (imbalance + generic overviews). TF-IDF still adds marginal signal to rating (tone, keywords). Dimensionality reduction prevents overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab0280-c494-4284-90fe-715f7f01381d",
   "metadata": {},
   "source": [
    "#### Best model that approximates the data, its pros and cons\n",
    "\n",
    "Gradient Boosted Trees - LightGBM\n",
    "\n",
    "- Why:\n",
    "    - excellent at handling heterogeneous tabular data, non-linear interactions, missing values, and mixed categorical/numeric features.\n",
    "    - Fast training and good default performance.\n",
    "\n",
    "- Pros:\n",
    "    - High predictive performance on tabular data.\n",
    "    - Handles non-linearities and interactions automatically.\n",
    "    - Works with target-encoded categorical features.\n",
    "    - Fast inference (production-friendly).\n",
    "\n",
    "- Cons:\n",
    "    - Less interpretable than a simple linear model\n",
    "    - Requires careful early stopping/hyperparameter tuning to avoid overfitting if dataset small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3164a-5a90-432e-b069-1b394621e954",
   "metadata": {},
   "source": [
    "#### Explaining the chosen model performance measure\n",
    "\n",
    "RMSE (Root Mean Squared Error)\n",
    "\n",
    "- Why:\n",
    "    - RMSE is the most common continuous error metric for rating prediction tasks\n",
    "    - RMSE penalizes larger errors more than MAE (Mean Squared Error), which is useful because being off by 1.0+ in IMDb rating is more important than being off by 0.1\n",
    "    - The resulted RMSE ≈ 0.091 means the model’s predictions are off by less than 0.1 rating points on average. In other words, if a movie’s true IMDb rating is 8.7, the model usually predicts somewhere between 8.6 and 8.8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adccd4-33d3-4dfc-b8de-8c18696e5125",
   "metadata": {},
   "source": [
    "#### 4. Predicted IMDb rating for 'The Shawshank Redemption': 8.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e3890-c1d5-457d-86a1-70e958484c6f",
   "metadata": {},
   "source": [
    "OBS.: `PProductions_Prediction.ipynb` notebook loads the model and predicts IMDb ratings for other titles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
